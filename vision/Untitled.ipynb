{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41f2ea6-0922-49b6-be51-17c86c7d9899",
   "metadata": {},
   "source": [
    "sewing machine, refrigerator, typewriter, Bookcase, Frame, lumber, TV, Audio, fax machine, chair, dish dryer, bicycle, arcade machine, TV stand, audio cabinet, Wardrobe, Display cabinet, Cupboard, Rice storage container, Stroller, Signboard, Washing machine, Speaker, Desk, Vanity table, Wall clock, Earthenware jar, Water tank, Air conditioner, Fan, Dining table, Small cabinet, Mannequin, Sink, Bedding items, Gas oven range, Heater, Cabinet, Drawer unit, Clothes drying rack, Toilet bowl, Spin dryer, Electric rice cooker, Kitchen sink, Shoe rack, Trunk, suitcase, Bathtub, Air purifier, Video player, Bed, Coat rack, Display stand, Floor covering, Microwave, Vacuum cleaner, Table, Sofa, Door panel, Mat, Bamboo mat, Computer ,Main unit, Monitor, Printer, Humidifier, Bookstand, Piano, Aquarium, Carpet, PP bag, General waste bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be12dee4-f1e5-4e94-a177-965333f6926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90967c98-4d27-47aa-ace2-e28ef8bd6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "0: \"sewing machine\",\n",
    "1: \"refrigerator\",\n",
    "2: \"typewriter\",\n",
    "3: \"Bookcase\",\n",
    "4: \"Frame\",\n",
    "5: \"lumber\",\n",
    "6: \"TV\",\n",
    "7: \"Audio\",\n",
    "8: \"fax machine\",\n",
    "9: \"chair\",\n",
    "10: \"dish dryer\",\n",
    "11: \"bicycle\",\n",
    "12: \"arcade machine\",\n",
    "13: \"TV stand\",\n",
    "14: \"audio cabinet\",\n",
    "15: \"Wardrobe\",\n",
    "16: \"Display cabinet\",\n",
    "17: \"Cupboard\",\n",
    "18: \"Rice storage container\",\n",
    "19: \"Stroller\",\n",
    "20: \"Signboard\",\n",
    "21: \"Washing machine\",\n",
    "22: \"Speaker\",\n",
    "23: \"Desk\",\n",
    "24: \"Vanity table\",\n",
    "25: \"Wall clock\",\n",
    "26: \"Earthenware jar\",\n",
    "27: \"Water tank\",\n",
    "28: \"Air conditioner\",\n",
    "29: \"Fan\",\n",
    "30: \"Dining table\",\n",
    "31: \"Small cabinet\",\n",
    "32: \"Mannequin\",\n",
    "33: \"Sink\",\n",
    "34: \"Bedding items\",\n",
    "35: \"Gas oven range\",\n",
    "36: \"Heater\",\n",
    "37: \"Cabinet\",\n",
    "38: \"Drawer unit\",\n",
    "39: \"Clothes drying rack\",\n",
    "40: \"Toilet bowl\",\n",
    "41: \"Spin dryer\",\n",
    "42: \"Electric rice cooker\",\n",
    "43: \"Kitchen sink\",\n",
    "44: \"Shoe rack\",\n",
    "45: \"Trunk, suitcase\",\n",
    "46: \"Bathtub\",\n",
    "47: \"Air purifier\",\n",
    "48: \"Video player\",\n",
    "49: \"Bed\",\n",
    "50: \"Coat rack\",\n",
    "51: \"Floor covering\",\n",
    "52: \"Microwave\",\n",
    "53: \"Vacuum cleaner\",\n",
    "54: \"Table\",\n",
    "55: \"Sofa\",\n",
    "56: \"Door panel\",\n",
    "57: \"Mat\",\n",
    "58: \"Bamboo mat\",\n",
    "59: \"Computer\",\n",
    "60: \"Main unit\",\n",
    "61: \"Monitor\",\n",
    "62: \"Printer\",\n",
    "63: \"Humidifier\",\n",
    "64: \"Bookstand\",\n",
    "65: \"Piano\",\n",
    "66: \"Aquarium\",\n",
    "67: \"Carpet\",\n",
    "68: \"PP bag\",\n",
    "69: \"General waste bag\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8412eb35-3e61-4344-854f-74f2935bf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    # 바운딩 박스 좌표 추출\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "\n",
    "    # 교차 영역 좌표 계산\n",
    "    x1_inter = max(x1_1, x1_2)\n",
    "    y1_inter = max(y1_1, y1_2)\n",
    "    x2_inter = min(x2_1, x2_2)\n",
    "    y2_inter = min(y2_1, y2_2)\n",
    "\n",
    "    # 교차 영역 넓이 계산\n",
    "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "\n",
    "    # 각 바운딩 박스의 넓이 계산\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "\n",
    "    # IoU 계산\n",
    "    iou_value = inter_area / (box1_area + box2_area - inter_area)\n",
    "    return iou_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a97bd4ba-e079-4158-8d49-f7961c8fdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
    "    # 신뢰도를 기준으로 내림차순 정렬\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    selected_boxes = []\n",
    "\n",
    "    while len(indices) > 0:\n",
    "        # 신뢰도가 가장 높은 바운딩 박스를 선택\n",
    "        current_box = boxes[indices[0]]\n",
    "        selected_boxes.append(indices[0])\n",
    "\n",
    "        # 나머지 바운딩 박스들과의 IoU 계산\n",
    "        remaining_indices = []\n",
    "        for i in indices[1:]:\n",
    "            if iou(current_box, boxes[i]) < iou_threshold:\n",
    "                remaining_indices.append(i)\n",
    "\n",
    "        # 신뢰도가 높은 것만 남기기\n",
    "        indices = remaining_indices\n",
    "\n",
    "    return selected_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f70d157-f246-419b-a3aa-9149d4eedbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, label):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"이미지를 불러올 수 없습니다: {image_path}\")\n",
    "        return\n",
    "\n",
    "    original_height, original_width = image.shape[:2]\n",
    "\n",
    "    # 모델 입력 크기에 맞게 이미지 조정\n",
    "    input_image = cv2.resize(image, (640, 640))  # YOLO-World 입력 크기에 맞게 조정\n",
    "    input_image = input_image.transpose(2, 0, 1)  # 채널 순서 변경 (HWC -> CHW)\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # 배치 차원 추가\n",
    "    input_image = input_image.astype(np.float32) / 255.0  # 정규화\n",
    "\n",
    "    # 입력 이름 확인\n",
    "    input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "    # 모델 실행\n",
    "    outputs = ort_session.run(None, {input_name: input_image})\n",
    "\n",
    "    # 출력 해석\n",
    "    boxes = outputs[1][0]  # 바운딩 박스 좌표 (640x640 이미지 기준)\n",
    "    scores = outputs[2][0]  # 신뢰도\n",
    "    class_ids = outputs[3][0]  # 클래스 ID\n",
    "    confidence_threshold = 0.2\n",
    "\n",
    "    # # 신뢰도가 임계값을 넘는 객체만 필터링\n",
    "    # filtered_indices = [i for i, score in enumerate(scores) if score > confidence_threshold]\n",
    "    # filtered_boxes = boxes[filtered_indices]\n",
    "    # filtered_scores = scores[filtered_indices]\n",
    "    # filtered_class_ids = class_ids[filtered_indices]\n",
    "\n",
    "    # # NMS 적용\n",
    "    # selected_indices = non_max_suppression(filtered_boxes, filtered_scores, iou_threshold=0.5)\n",
    "\n",
    "    # # 다수의 객체를 처리하는 반복문\n",
    "    # for i in selected_indices:\n",
    "    #     x1, y1, x2, y2 = filtered_boxes[i]  # 바운딩 박스 좌표 (640x640 기준)\n",
    "        \n",
    "    #     # 바운딩 박스 좌표를 원본 이미지 크기에 맞게 변환\n",
    "    #     x1 = int(x1 / 640 * original_width)\n",
    "    #     y1 = int(y1 / 640 * original_height)\n",
    "    #     x2 = int(x2 / 640 * original_width)\n",
    "    #     y2 = int(y2 / 640 * original_height)\n",
    "        \n",
    "    #     class_name = class_labels.get(int(filtered_class_ids[i]), 'Unknown')\n",
    "    #     label = f\"{class_name} {filtered_scores[i]:.2f}\"\n",
    "\n",
    "    #     # 색상 지정\n",
    "    #     color = (0, 255, 0)  # 초록색\n",
    "    #     cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)  # 바운딩 박스 그리기\n",
    "    #     cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # # 결과 이미지 표시\n",
    "    # cv2.imshow('Result', image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # 검출된 객체 정보 출력\n",
    "    # print(f\"이미지: {image_path}\")\n",
    "    # print(\"검출된 객체 정보:\")\n",
    "    for i in range(len(class_ids)):\n",
    "        class_name = class_labels.get(int(class_ids[i]), 'Unknown')\n",
    "        \n",
    "        # print(f\"클래스 ID: {class_name}, 신뢰도: {filtered_scores[i]:.2f}\")\n",
    "        if class_name == label:\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "    # print('-------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "619be21c-2a71-4f7b-8104-18141c1afccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        sum_t = 0\n",
    "        sum_f = 0\n",
    "        count = 1\n",
    "        # 현재 폴더의 이름을 가져온다\n",
    "        current_folder_name = os.path.basename(root)\n",
    "        \n",
    "        for filename in files:\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(root, filename)\n",
    "                \n",
    "                if process_image(image_path, current_folder_name):\n",
    "                    sum_t += 1\n",
    "                else:\n",
    "                    sum_f += 1\n",
    "                \n",
    "                # 폴더 이름과 파일 이름을 함께 출력\n",
    "                print(f\"Folder: {current_folder_name}, File: {filename}, Count: {count}\")\n",
    "                count += 1\n",
    "    \n",
    "        print(sum_t, sum_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7220c84d-a2ec-4f7a-911f-6e2f4670f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "Folder: lumber, File: 13_X001_C162_1215_1.jpg, Count: 1\n",
      "Folder: lumber, File: 13_X001_C808_0924_3.jpg, Count: 2\n",
      "Folder: lumber, File: 13_X001_C808_0924_2.jpg, Count: 3\n",
      "Folder: lumber, File: 13_X001_C162_1215_0.jpg, Count: 4\n",
      "Folder: lumber, File: 13_X001_C162_1215_2.jpg, Count: 5\n",
      "Folder: lumber, File: 13_X001_C808_0924_0.jpg, Count: 6\n",
      "Folder: lumber, File: 13_X001_C808_0924_1.jpg, Count: 7\n",
      "Folder: lumber, File: 13_X001_C162_1215_3.jpg, Count: 8\n",
      "Folder: lumber, File: 13_X001_C808_0924_4.jpg, Count: 9\n",
      "Folder: lumber, File: 13_X001_C162_1215_4.jpg, Count: 10\n",
      "Folder: lumber, File: 13_X001_C211_1201_4.jpg, Count: 11\n",
      "Folder: lumber, File: 13_X001_C162_1214_2.jpg, Count: 12\n",
      "Folder: lumber, File: 13_X001_C162_1214_3.jpg, Count: 13\n",
      "Folder: lumber, File: 13_X001_C162_1214_1.jpg, Count: 14\n",
      "Folder: lumber, File: 13_X001_C189_1216_4.jpg, Count: 15\n",
      "Folder: lumber, File: 13_X001_C162_1214_0.jpg, Count: 16\n",
      "Folder: lumber, File: 13_X001_C211_1201_2.jpg, Count: 17\n",
      "Folder: lumber, File: 13_X001_C189_1216_1.jpg, Count: 18\n",
      "Folder: lumber, File: 13_X001_C162_1214_4.jpg, Count: 19\n",
      "Folder: lumber, File: 13_X001_C189_1216_0.jpg, Count: 20\n",
      "Folder: lumber, File: 13_X001_C211_1201_3.jpg, Count: 21\n",
      "Folder: lumber, File: 13_X001_C211_1201_1.jpg, Count: 22\n",
      "Folder: lumber, File: 13_X001_C189_1216_2.jpg, Count: 23\n",
      "Folder: lumber, File: 13_X001_C189_1216_3.jpg, Count: 24\n",
      "Folder: lumber, File: 13_X001_C211_1201_0.jpg, Count: 25\n",
      "Folder: lumber, File: 13_X001_C806_0925_4.jpg, Count: 26\n",
      "Folder: lumber, File: 13_X001_C323_0131_2.jpg, Count: 27\n",
      "Folder: lumber, File: 13_X001_C704_1215_4.jpg, Count: 28\n",
      "Folder: lumber, File: 13_X001_C323_0131_3.jpg, Count: 29\n",
      "Folder: lumber, File: 13_X001_C058_1207_4.jpg, Count: 30\n",
      "Folder: lumber, File: 13_X002_C055_1211_4.jpg, Count: 31\n",
      "Folder: lumber, File: 13_X001_C195_1205_4.jpg, Count: 32\n",
      "Folder: lumber, File: 13_X001_C058_0203_2.jpg, Count: 33\n",
      "Folder: lumber, File: 13_X001_C195_1207_4.jpg, Count: 34\n",
      "Folder: lumber, File: 13_X001_C163_1215_4.jpg, Count: 35\n",
      "Folder: lumber, File: 13_X001_C323_0131_1.jpg, Count: 36\n",
      "Folder: lumber, File: 13_X001_C323_0131_0.jpg, Count: 37\n",
      "Folder: lumber, File: 13_X001_C204_1021_4.jpg, Count: 38\n",
      "Folder: lumber, File: 13_X001_C058_0203_3.jpg, Count: 39\n",
      "Folder: lumber, File: 13_X001_C195_1205_3.jpg, Count: 40\n",
      "Folder: lumber, File: 13_X001_C806_0925_2.jpg, Count: 41\n",
      "Folder: lumber, File: 13_X001_C195_1207_1.jpg, Count: 42\n",
      "Folder: lumber, File: 13_X002_C055_1211_3.jpg, Count: 43\n",
      "Folder: lumber, File: 13_X001_C204_1021_0.jpg, Count: 44\n",
      "Folder: lumber, File: 13_X001_C163_1215_1.jpg, Count: 45\n",
      "Folder: lumber, File: 13_X001_C058_1207_3.jpg, Count: 46\n",
      "Folder: lumber, File: 13_X001_C704_1215_3.jpg, Count: 47\n",
      "Folder: lumber, File: 13_X001_C323_0131_4.jpg, Count: 48\n",
      "Folder: lumber, File: 13_X001_C704_1215_2.jpg, Count: 49\n",
      "Folder: lumber, File: 13_X001_C058_1207_2.jpg, Count: 50\n",
      "Folder: lumber, File: 13_X001_C163_1215_0.jpg, Count: 51\n",
      "Folder: lumber, File: 13_X001_C204_1021_1.jpg, Count: 52\n",
      "Folder: lumber, File: 13_X002_C055_1211_2.jpg, Count: 53\n",
      "Folder: lumber, File: 13_X001_C195_1207_0.jpg, Count: 54\n",
      "Folder: lumber, File: 13_X001_C806_0925_3.jpg, Count: 55\n",
      "Folder: lumber, File: 13_X001_C058_0203_6.jpg, Count: 56\n",
      "Folder: lumber, File: 13_X001_C195_1205_2.jpg, Count: 57\n",
      "Folder: lumber, File: 13_X001_C806_0925_1.jpg, Count: 58\n",
      "Folder: lumber, File: 13_X001_C195_1205_0.jpg, Count: 59\n",
      "Folder: lumber, File: 13_X001_C058_0203_4.jpg, Count: 60\n",
      "Folder: lumber, File: 13_X002_C055_1211_0.jpg, Count: 61\n",
      "Folder: lumber, File: 13_X001_C195_1207_2.jpg, Count: 62\n",
      "Folder: lumber, File: 13_X001_C204_1021_3.jpg, Count: 63\n",
      "Folder: lumber, File: 13_X001_C163_1215_2.jpg, Count: 64\n",
      "Folder: lumber, File: 13_X001_C058_1207_0.jpg, Count: 65\n",
      "Folder: lumber, File: 13_X001_C704_1215_0.jpg, Count: 66\n",
      "Folder: lumber, File: 13_X001_C704_1215_1.jpg, Count: 67\n",
      "Folder: lumber, File: 13_X001_C058_1207_1.jpg, Count: 68\n",
      "Folder: lumber, File: 13_X001_C163_1215_3.jpg, Count: 69\n",
      "Folder: lumber, File: 13_X001_C204_1021_2.jpg, Count: 70\n",
      "Folder: lumber, File: 13_X001_C195_1207_3.jpg, Count: 71\n",
      "Folder: lumber, File: 13_X002_C055_1211_1.jpg, Count: 72\n",
      "Folder: lumber, File: 13_X001_C058_0203_5.jpg, Count: 73\n",
      "Folder: lumber, File: 13_X001_C195_1205_1.jpg, Count: 74\n",
      "Folder: lumber, File: 13_X001_C806_0925_0.jpg, Count: 75\n",
      "Folder: lumber, File: 13_X001_C706_1215_4.jpg, Count: 76\n",
      "Folder: lumber, File: 13_X002_C038_1116_1.jpg, Count: 77\n",
      "Folder: lumber, File: 13_X001_C187_1215_2.jpg, Count: 78\n",
      "Folder: lumber, File: 13_X001_C187_1215_3.jpg, Count: 79\n",
      "Folder: lumber, File: 13_X002_C038_1116_0.jpg, Count: 80\n",
      "Folder: lumber, File: 13_X001_C509_0126_4.jpg, Count: 81\n",
      "Folder: lumber, File: 13_X002_C038_1116_2.jpg, Count: 82\n",
      "Folder: lumber, File: 13_X001_C187_1215_1.jpg, Count: 83\n",
      "Folder: lumber, File: 13_X001_C187_1215_0.jpg, Count: 84\n",
      "Folder: lumber, File: 13_X001_C058_1027_4.jpg, Count: 85\n",
      "Folder: lumber, File: 13_X002_C038_1116_3.jpg, Count: 86\n",
      "Folder: lumber, File: 13_X001_C706_1215_2.jpg, Count: 87\n",
      "Folder: lumber, File: 13_X001_C509_0126_3.jpg, Count: 88\n",
      "Folder: lumber, File: 13_X001_C058_1027_0.jpg, Count: 89\n",
      "Folder: lumber, File: 13_X001_C187_1215_4.jpg, Count: 90\n",
      "Folder: lumber, File: 13_X001_C058_1027_1.jpg, Count: 91\n",
      "Folder: lumber, File: 13_X001_C509_0126_2.jpg, Count: 92\n",
      "Folder: lumber, File: 13_X001_C706_1215_3.jpg, Count: 93\n",
      "Folder: lumber, File: 13_X001_C706_1215_1.jpg, Count: 94\n",
      "Folder: lumber, File: 13_X001_C509_0126_0.jpg, Count: 95\n",
      "Folder: lumber, File: 13_X002_C038_1116_4.jpg, Count: 96\n",
      "Folder: lumber, File: 13_X001_C058_1027_3.jpg, Count: 97\n",
      "Folder: lumber, File: 13_X001_C058_1027_2.jpg, Count: 98\n",
      "Folder: lumber, File: 13_X001_C509_0126_1.jpg, Count: 99\n",
      "Folder: lumber, File: 13_X001_C706_1215_0.jpg, Count: 100\n",
      "47 53\n",
      "Folder: tv, File: 20_X001_C508_1021_5_0.jpg, Count: 1\n",
      "Folder: tv, File: 20_X001_C324_1224_0.jpg, Count: 2\n",
      "Folder: tv, File: 20_X002_C013_1223_3.jpg, Count: 3\n",
      "Folder: tv, File: 20_X001_C058_1111_2.jpg, Count: 4\n",
      "Folder: tv, File: 20_X001_C331_1028_3.jpg, Count: 5\n",
      "Folder: tv, File: 20_X001_C331_1028_2.jpg, Count: 6\n",
      "Folder: tv, File: 20_X001_C058_1111_3.jpg, Count: 7\n",
      "Folder: tv, File: 20_X002_C013_1223_2.jpg, Count: 8\n",
      "Folder: tv, File: 20_X001_C324_1224_1.jpg, Count: 9\n",
      "Folder: tv, File: 20_X001_C508_1021_5_1.jpg, Count: 10\n",
      "Folder: tv, File: 20_X001_C508_1021_5_3.jpg, Count: 11\n",
      "Folder: tv, File: 20_X001_C324_1224_3.jpg, Count: 12\n",
      "Folder: tv, File: 20_X002_C013_1223_0.jpg, Count: 13\n",
      "Folder: tv, File: 20_X001_C058_1111_1.jpg, Count: 14\n",
      "Folder: tv, File: 20_X001_C331_1028_0.jpg, Count: 15\n",
      "Folder: tv, File: 20_X001_C331_1028_1.jpg, Count: 16\n",
      "Folder: tv, File: 20_X001_C058_1111_0.jpg, Count: 17\n",
      "Folder: tv, File: 20_X002_C013_1223_1.jpg, Count: 18\n",
      "Folder: tv, File: 20_X001_C324_1224_2.jpg, Count: 19\n",
      "Folder: tv, File: 20_X001_C508_1021_5_2.jpg, Count: 20\n",
      "Folder: tv, File: 20_X001_C058_1111_4.jpg, Count: 21\n",
      "Folder: tv, File: 20_X001_C331_1028_4.jpg, Count: 22\n",
      "Folder: tv, File: 20_X002_C013_1223_4.jpg, Count: 23\n",
      "Folder: tv, File: 20_X001_C324_1224_4.jpg, Count: 24\n",
      "Folder: tv, File: 20_X001_C508_1021_5_4.jpg, Count: 25\n",
      "Folder: tv, File: 20_X001_C058_0213_3.jpg, Count: 26\n",
      "Folder: tv, File: 20_X001_C332_1127_4.jpg, Count: 27\n",
      "Folder: tv, File: 20_X001_C058_0213_2.jpg, Count: 28\n",
      "Folder: tv, File: 20_X001_C058_0213_0.jpg, Count: 29\n",
      "Folder: tv, File: 20_X001_C058_0213_1.jpg, Count: 30\n",
      "Folder: tv, File: 20_X001_C332_1127_2.jpg, Count: 31\n",
      "Folder: tv, File: 20_X001_C332_1127_3.jpg, Count: 32\n",
      "Folder: tv, File: 20_X001_C058_0213_4.jpg, Count: 33\n",
      "Folder: tv, File: 20_X001_C332_1127_1.jpg, Count: 34\n",
      "Folder: tv, File: 20_X001_C332_1127_0.jpg, Count: 35\n",
      "Folder: tv, File: 20_X001_C055_1204_4.jpg, Count: 36\n",
      "Folder: tv, File: 20_X001_C055_1204_1.jpg, Count: 37\n",
      "Folder: tv, File: 20_X001_C055_1204_0.jpg, Count: 38\n",
      "Folder: tv, File: 20_X001_C055_1204_2.jpg, Count: 39\n",
      "Folder: tv, File: 20_X001_C055_1204_3.jpg, Count: 40\n",
      "Folder: tv, File: 20_X001_C328_1106_1.jpg, Count: 41\n",
      "Folder: tv, File: 20_X001_C055_1019_4.jpg, Count: 42\n",
      "Folder: tv, File: 20_X001_C328_1106_0.jpg, Count: 43\n",
      "Folder: tv, File: 20_X001_C328_1106_2.jpg, Count: 44\n",
      "Folder: tv, File: 20_X001_C328_1106_3.jpg, Count: 45\n",
      "Folder: tv, File: 20_X001_C055_1019_2.jpg, Count: 46\n",
      "Folder: tv, File: 20_X001_C055_1019_3.jpg, Count: 47\n",
      "Folder: tv, File: 20_X001_C328_1106_4.jpg, Count: 48\n",
      "Folder: tv, File: 20_X001_C055_1019_1.jpg, Count: 49\n",
      "Folder: tv, File: 20_X001_C055_1019_0.jpg, Count: 50\n",
      "0 50\n"
     ]
    }
   ],
   "source": [
    "ort_session = ort.InferenceSession(\"yolow-l.onnx\")\n",
    "folder_path = \"images\"  # 이미지가 저장된 폴더 경로 입력\n",
    "process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49445c64-d7a9-4d98-b6cf-569c1a430c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ONNX 모델 로드\n",
    "ort_session = ort.InferenceSession(\"yolow-l.onnx\")\n",
    "\n",
    "# 입력 이미지 준비\n",
    "image_path = '148514863_1_1727006732_w480.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "original_height, original_width = image.shape[:2]\n",
    "\n",
    "# 모델 입력 크기에 맞게 이미지 조정\n",
    "input_image = cv2.resize(image, (640, 640))  # YOLO-World 입력 크기에 맞게 조정\n",
    "input_image = input_image.transpose(2, 0, 1)  # 채널 순서 변경 (HWC -> CHW)\n",
    "input_image = np.expand_dims(input_image, axis=0)  # 배치 차원 추가\n",
    "input_image = input_image.astype(np.float32) / 255.0  # 정규화\n",
    "\n",
    "# 입력 이름 확인\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "# 모델 실행\n",
    "outputs = ort_session.run(None, {input_name: input_image})\n",
    "\n",
    "# 출력 해석\n",
    "boxes = outputs[1][0]  # 바운딩 박스 좌표 (640x640 이미지 기준)\n",
    "scores = outputs[2][0]  # 신뢰도\n",
    "class_ids = outputs[3][0]  # 클래스 ID\n",
    "confidence_threshold = 0.2\n",
    "class_name = np.empty(class_ids.shape, dtype=object)\n",
    "\n",
    "# 신뢰도가 임계값을 넘는 객체만 필터링\n",
    "filtered_indices = [i for i, score in enumerate(scores) if score > confidence_threshold]\n",
    "filtered_boxes = boxes[filtered_indices]\n",
    "filtered_scores = scores[filtered_indices]\n",
    "filtered_class_ids = class_ids[filtered_indices]\n",
    "\n",
    "# NMS 적용\n",
    "selected_indices = non_max_suppression(filtered_boxes, filtered_scores, iou_threshold=0.5)\n",
    "\n",
    "# 다수의 객체를 처리하는 반복문\n",
    "for i in selected_indices:\n",
    "    x1, y1, x2, y2 = filtered_boxes[i]  # 바운딩 박스 좌표 (640x640 기준)\n",
    "    \n",
    "    # 바운딩 박스 좌표를 원본 이미지 크기에 맞게 변환\n",
    "    x1 = int(x1 / 640 * original_width)\n",
    "    y1 = int(y1 / 640 * original_height)\n",
    "    x2 = int(x2 / 640 * original_width)\n",
    "    y2 = int(y2 / 640 * original_height)\n",
    "    \n",
    "    class_name[i] = class_labels.get(int(filtered_class_ids[i]), 'Unknown')\n",
    "    label = f\"{class_name[i]} {filtered_scores[i]:.2f}\"\n",
    "\n",
    "    # 색상 지정\n",
    "    color = (0, 255, 0)  # 초록색\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)  # 바운딩 박스 그리기\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "# 결과 이미지 표시\n",
    "cv2.imshow('Result', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 검출된 객체 정보 출력\n",
    "print(\"검출된 객체 정보:\")\n",
    "for i in selected_indices:\n",
    "    print(f\"클래스 ID: {class_name[i]}, 신뢰도: {filtered_scores[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57b441-857c-45c8-9778-ee34b1c57d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ONNX 모델 로드\n",
    "ort_session = ort.InferenceSession(\"yolow-l.onnx\")\n",
    "\n",
    "# 이미지가 저장된 폴더 경로\n",
    "folder_path = 'image'\n",
    "\n",
    "# 폴더 내 모든 파일 반복\n",
    "for filename in os.listdir(folder_path):\n",
    "    # 파일의 확장자가 이미지 형식인지 확인\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "        image_path = os.path.join(folder_path, filename)  # 전체 이미지 경로\n",
    "\n",
    "        # 입력 이미지 준비\n",
    "        image = cv2.imread(image_path)\n",
    "        original_height, original_width = image.shape[:2]\n",
    "\n",
    "        # 모델 입력 크기에 맞게 이미지 조정\n",
    "        input_image = cv2.resize(image, (640, 640))  # YOLO-World 입력 크기에 맞게 조정\n",
    "        input_image = input_image.transpose(2, 0, 1)  # 채널 순서 변경 (HWC -> CHW)\n",
    "        input_image = np.expand_dims(input_image, axis=0)  # 배치 차원 추가\n",
    "        input_image = input_image.astype(np.float32) / 255.0  # 정규화\n",
    "\n",
    "        # 입력 이름 확인\n",
    "        input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "        # 모델 실행\n",
    "        outputs = ort_session.run(None, {input_name: input_image})\n",
    "\n",
    "        # 출력 해석\n",
    "        boxes = outputs[1][0]  # 바운딩 박스 좌표 (640x640 이미지 기준)\n",
    "        scores = outputs[2][0]  # 신뢰도\n",
    "        class_ids = outputs[3][0]  # 클래스 ID\n",
    "        confidence_threshold = 0.1\n",
    "\n",
    "        # 다수의 객체를 처리하는 반복문\n",
    "        for i in range(len(scores)):\n",
    "            score = scores[i]\n",
    "            if score > confidence_threshold:  # 신뢰도가 임계값보다 높은 객체만 처리\n",
    "                x1, y1, x2, y2 = boxes[i]  # 바운딩 박스 좌표 (640x640 기준)\n",
    "\n",
    "                # 바운딩 박스 좌표를 원본 이미지 크기에 맞게 변환\n",
    "                x1 = int(x1 / 640 * original_width)\n",
    "                y1 = int(y1 / 640 * original_height)\n",
    "                x2 = int(x2 / 640 * original_width)\n",
    "                y2 = int(y2 / 640 * original_height)\n",
    "\n",
    "                class_id = int(class_ids[i])  # 클래스 ID\n",
    "                label = f\"Class {class_id} {score:.2f}\"\n",
    "\n",
    "                # 색상 지정\n",
    "                color = (0, 255, 0)  # 초록색\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)  # 바운딩 박스 그리기\n",
    "                cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Result', image)\n",
    "        cv2.waitKey(0)  # 결과 창에서 키 입력을 기다림\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # 검출된 객체 정보 출력\n",
    "        print(f\"파일: {filename}\")\n",
    "        print(\"검출된 객체 정보:\")\n",
    "        for i in range(len(scores)):\n",
    "            score = scores[i]\n",
    "            if score > confidence_threshold:\n",
    "                class_id = int(class_ids[i])\n",
    "                print(f\"클래스 ID: {class_id}, 신뢰도: {score:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
